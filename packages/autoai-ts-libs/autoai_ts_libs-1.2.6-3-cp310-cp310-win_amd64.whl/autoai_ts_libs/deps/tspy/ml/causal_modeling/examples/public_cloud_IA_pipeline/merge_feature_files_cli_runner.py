#  /************** Begin Copyright - Do not add comments here **************
#   * Licensed Materials - Property of IBM
#   *
#   *   OCO Source Materials
#   *
#   *   (C) Copyright IBM Corp. 2020, All Rights Reserved
#   *
#   * The source code for this program is not published or other-
#   * wise divested of its trade secrets, irrespective of what has
#   * been deposited with the U.S. Copyright Office.
#   ***************************** End Copyright ****************************/
"""
Command-line tool to merge multiple HDF5 files generated by 'oculus_features_cli_runner.py'.
Merging may be needed when generating features on a datacenter basis (separately for each DC).
"""
import h5py as h5
import argparse
import pickle
import numpy as np

append_keys = ['X_train', 'X_dev', 'X_test', 'Y_train', 'Y_dev', 'Y_test']
collateral_keys = ['trainset_info', 'devset_info', 'testset_info']   # these need decoding before append

parser = argparse.ArgumentParser(description="Merge multiple fea files")
parser.add_argument('-i', '--inFof', dest='foffn', required=True, metavar='<fof>',
                    help="List of files (fof) to be merged")
parser.add_argument('-o', '--o', dest='outfn', required=True, metavar='<outfn>',
                    help="Output file in hdf5 format.")
args = parser.parse_args()

poolfn = args.outfn
fof = args.foffn
with open(fof, 'rt') as f:
    foflst = f.readlines()
foflst = [i.strip() for i in foflst]

first = True
D_collateral = {}
with h5.File(poolfn, 'w') as of:
    for k in collateral_keys:
        D_collateral[k] = []
    for infn in foflst:
        with h5.File(infn, 'r') as f:
            skip = False
            for k in append_keys:
                if k not in f.keys():
                    print("WARN: Skipping %s due to missing key %s" % (infn, k))
                    skip = True
                    break
            if skip:
                continue
            print("INFO: Processing input file %s" % infn)
            for k in collateral_keys:
                if k in f:
                    D_collateral[k].append(pickle.loads(f[k][()]))
            if first:
                # copy everything
                for k in f.keys():
                    if k in append_keys:
                        of.create_dataset(k, data=f[k][()], maxshape=[None]+list(f[k].shape)[1:])
                    elif k in collateral_keys:
                        pass
                    else:
                        of.create_dataset(k, data=f[k][()])
                first = False
            else:
                # append data
                for k in append_keys:
                    of[k].resize((of[k].shape[0] + f[k].shape[0]), axis=0)
                    of[k][-f[k].shape[0]:] = f[k]
    if len(D_collateral) > 0:
        for k in collateral_keys:
            if len(D_collateral[k]) < 1:
                print("WARN: Could not find any content for collateral info key=%s SKIPPING (check the source files)" % k)
                break
            newd = np.concatenate(D_collateral[k], axis=0)
            xaux = np.fromstring(pickle.dumps(newd), dtype='uint8')
            of.create_dataset(k, data=xaux)
    print("INFO: Created a pool file with X_train shape=%s" % str(of['X_train'].shape))
