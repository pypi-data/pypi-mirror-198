Metadata-Version: 2.1
Name: supertransformerlib
Version: 2.4.0
Summary: A set of tools for performing ensemble based supertransformer
Keywords: torch,transformer,transformers
Author-email: Christopher M O'Quinn <chrisoquinn.2@gmail.com>
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: torch >= 1.11
Requires-Dist: numpy
Requires-Dist: flit
Requires-Dist: pytest ; extra == "doc"
Project-URL: Documentation, https://torch-supertransformerlib.readthedocs.io/en/latest/
Project-URL: Source, https://github.com/smithblack-0/torch-supertransformerlib
Provides-Extra: doc

[![Python test then publish](https://github.com/smithblack-0/torch-supertransformerlib/actions/workflows/python-test-publish.yml/badge.svg?branch=master)](https://github.com/smithblack-0/torch-supertransformerlib/actions/workflows/python-test-publish.yml)


# What is this?

This is a collection of layers designed to achieve state-of-the-art results in the field of natural language processing.
It consists of a collection of layers, loss functions,
and utilities which either implement recent transformer discoveries,
or which have no analogue in the current NLP literature. It is built in torch.

The library primarily forcuses around working
with the word embeddings.

It has the following desirable properties when used correctly

* torchscript compatible
* O(N) with respect to words input (configured correctly)
* Ensembles natively supported.

## Documentation

See https://torch-supertransformerlib.readthedocs.io/en/latest/ for documentation

